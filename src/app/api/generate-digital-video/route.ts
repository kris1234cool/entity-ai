import { NextResponse } from 'next/server';
import OSS from 'ali-oss';

export const runtime = 'nodejs';

// ç¯å¢ƒå˜é‡
const DASHSCOPE_API_KEY = process.env.DASHSCOPE_API_KEY!;
const OSS_REGION = process.env.NEXT_PUBLIC_OSS_REGION!;
const OSS_ACCESS_KEY_ID = process.env.NEXT_PUBLIC_OSS_ACCESS_KEY_ID!;
const OSS_ACCESS_KEY_SECRET = process.env.NEXT_PUBLIC_OSS_ACCESS_KEY_SECRET!;
const OSS_BUCKET = process.env.NEXT_PUBLIC_OSS_BUCKET!;

const ossClient = new OSS({
  region: OSS_REGION,
  accessKeyId: OSS_ACCESS_KEY_ID,
  accessKeySecret: OSS_ACCESS_KEY_SECRET,
  bucket: OSS_BUCKET,
  secure: true,
});

/**
 * éŸ³è‰²å“ç‰ŒåŒ–æ˜ å°„ï¼šå‰ç«¯åç§° -> é˜¿é‡Œäº‘ Voice ID
 * æ”¯æŒ 6 ä¸ªæ ¸å¿ƒå“ç‰ŒéŸ³è‰² (3ç”·3å¥³)
 */
const VOICE_NAME_MAP: Record<string, string> = {
  // å¥³å£°
  "é›…é›…": "longxiaochun",
  "å°å¨©": "longxiaowan",
  "ç™½ç™½": "longyebai",
  // ç”·å£°
  "ä¸¥é€‰ç”·å£°": "longcheng",
  "è€é“": "longlaotie",
  "é¾™é£": "longfei",
};

/**
 * è§£æéŸ³è‰²IDï¼šæ”¯æŒå“ç‰Œåç§°æˆ–ç›´æ¥ä¼ å…¥æŠ€æœ¯ID
 */
function resolveVoiceId(voiceInput: string): string {
  return VOICE_NAME_MAP[voiceInput] || voiceInput;
}

/**
 * æƒ…æ„ŸåŒ–æ–‡æœ¬é¢„å¤„ç†ï¼šå°†æ ‡ç­¾æ˜ å°„ä¸ºèƒ½å¤Ÿå¼•å¯¼ CosyVoice æƒ…æ„Ÿèµ·ä¼çš„æ ‡ç‚¹
 */
function preprocessText(text: string): string {
  let processed = text;
  
  // 1. è¿‡æ»¤å¹²æ‰°åˆæˆçš„ç‰¹æ®Šç¬¦å·
  processed = processed.replace(/[\u{1F600}-\u{1F64F}\u{1F300}-\u{1F5FF}\u{1F680}-\u{1F6FF}\u{1F1E6}-\u{1F1FF}\u{2600}-\u{26FF}\u{2700}-\u{27BF}\u{1F900}-\u{1F9FF}\u{1F3FB}-\u{1F3FF}\u{200D}\u{200B}\u{200E}\u{200F}\u{FE0F}\u{1F000}-\u{1F02B}\u{1F030}-\u{1F093}ğŸ¼]/gu, '');
  
  // 2. æƒ…æ„Ÿæ˜ å°„ (åˆ©ç”¨æ ‡ç‚¹ç¬¦å·æ§åˆ¶ prosody)
  processed = processed.replace(/\[åœé¡¿\d+(ms|s)\]/g, 'â€¦â€¦ ');
  processed = processed.replace(/\[å¸æ°”\]/g, 'ï¼Œ');
  processed = processed.replace(/\[(æ€è€ƒ|å¹æ°”)\]/g, ' â€”â€” ');
  processed = processed.replace(/\[é‡è¯»\]/g, 'ï¼');
  processed = processed.replace(/\[æ…¢è¯»\]/g, 'â€¦â€¦ ');
  
  // 3. è§„èŒƒåŒ–å¤„ç†
  processed = processed.replace(/ï¼Ÿ{2,}/g, 'ï¼Ÿ');
  processed = processed.replace(/ï¼{2,}/g, 'ï¼');
  processed = processed.replace(/ã€‚{2,}/g, 'ã€‚');
  processed = processed.replace(/â€¦â€¦{2,}/g, 'â€¦â€¦');
  
  return processed.trim();
}

/**
 * POST: ç”Ÿæˆæ•°å­—äººå£æ’­è§†é¢‘
 * Body: { text: string, voice_id: string, video_url: string, model?: string }
 */
export async function POST(req: Request) {
  try {
    const { text, voice_id, video_url, model = "cosyvoice-v3-plus" } = await req.json();

    if (!text || !voice_id || !video_url) {
      return NextResponse.json({ error: "Missing parameters: text, voice_id, video_url required" }, { status: 400 });
    }

    const resolvedVoiceId = resolveVoiceId(voice_id);
    const processedText = preprocessText(text);
    
    // 1. è°ƒç”¨é˜¿é‡Œäº‘ TTS REST API (çº¯å†…å­˜æµå¤„ç†ï¼Œæ— ç£ç›˜IO)
    console.log("ğŸ™ï¸ Generating TTS via REST API...");
    const ttsResponse = await fetch(
      "https://dashscope.aliyuncs.com/api/v1/services/audio/tts/synthesis",
      {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${DASHSCOPE_API_KEY}`,
          "Content-Type": "application/json",
          "X-DashScope-Data-Inspection": "enable"
        },
        body: JSON.stringify({
          model: model,
          input: { text: processedText },
          parameters: { 
            voice: resolvedVoiceId,
            format: "mp3",
            sample_rate: 24000
          }
        })
      }
    );

    if (!ttsResponse.ok) {
      const errorText = await ttsResponse.text();
      console.error("TTS API Error Details:", errorText);
      throw new Error(`TTS API Error: ${errorText}`);
    }

    const audioArrayBuffer = await ttsResponse.arrayBuffer();
    // ä½¿ç”¨ Buffer.from æ˜¾å¼åˆ›å»ºå†…å­˜ Buffer
    const audioBuffer = Buffer.from(audioArrayBuffer);
    const audioFilename = `gen_audio_${Date.now()}.mp3`;

    // 2. ä¸Šä¼ éŸ³é¢‘åˆ° é˜¿é‡Œäº‘ OSS (å†…å­˜ç›´ä¼ ï¼Œå½»åº•ç§»é™¤ fs ä¾èµ–)
    console.log("ğŸ“¦ Uploading audio to OSS (Memory Mode)...");
    await ossClient.put(audioFilename, audioBuffer);
    
    // æ„é€ å…¬ç½‘è®¿é—® URL
    const audio_final_url = `https://${OSS_BUCKET}.${OSS_REGION}.aliyuncs.com/${audioFilename}`;
    console.log("âœ… Audio uploaded to OSS:", audio_final_url);

    // 3. è°ƒç”¨ VideoRetalk API åˆæˆè§†é¢‘ (Async)
    console.log("ğŸ¬ Calling VideoRetalk API...");
    const videoResponse = await fetch(
      "https://dashscope.aliyuncs.com/api/v1/services/aigc/image2video/video-synthesis",
      {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${DASHSCOPE_API_KEY}`,
          "Content-Type": "application/json",
          "X-DashScope-Async": "enable"
        },
        body: JSON.stringify({
          model: "videoretalk",
          input: { 
            video_url: video_url, 
            audio_url: audio_final_url 
          },
          parameters: { 
            video_extension: false 
          }
        })
      }
    );

    if (!videoResponse.ok) {
      const errorText = await videoResponse.text();
      console.error("VideoRetalk API Error Details:", errorText);
      throw new Error(`Aliyun VideoRetalk API Error: ${errorText}`);
    }
    
    const videoData = await videoResponse.json();
    return NextResponse.json({
      success: true,
      task_id: videoData.output?.task_id,
      audio_url: audio_final_url,
      ...videoData
    });

  } catch (error: any) {
    console.error("Generate Digital Video Error:", error);
    return NextResponse.json({ error: error.message || 'Unknown error' }, { status: 500 });
  }
}
